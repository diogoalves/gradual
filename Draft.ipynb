{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para utilizar o c√≥digo em outros modulos sem a necessidade de ficar reiniciando o notebook.\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gradual.engine import Value, Tensor\n",
    "from gradual.util import draw_dot\n",
    "import torch \n",
    "import numpy as np \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_sanity_check():\n",
    "\n",
    "    x = Tensor([-4.0])\n",
    "    z = [2] * x + [2] + x\n",
    "    q = z.relu() + z * x\n",
    "    h = (z * z).relu()\n",
    "    y = h + q + q * x\n",
    "    y.backward()\n",
    "    xmg, ymg = x, y\n",
    "\n",
    "    x = torch.Tensor([-4.0]).double()\n",
    "    x.requires_grad = True\n",
    "    z = 2 * x + 2 + x\n",
    "    q = z.relu() + z * x\n",
    "    h = (z * z).relu()\n",
    "    y = h + q + q * x\n",
    "    y.backward()\n",
    "    xpt, ypt = x, y\n",
    "\n",
    "    # forward pass went well\n",
    "    assert ymg.data == ypt.data.item()\n",
    "    # backward pass went well\n",
    "    assert xmg.grad == xpt.grad.item()\n",
    "\n",
    "test_sanity_check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diogoalves/work/gradual/gradual/engine.py:138: RuntimeWarning: invalid value encountered in log\n",
      "  other.grad += ((self.data ** other.data) * np.log(self.data)) * out.grad\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "non-broadcastable output operand with shape () doesn't match the broadcast shape (1,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 43\u001b[0m\n\u001b[1;32m     31\u001b[0m     g \u001b[39m=\u001b[39m g \u001b[39m+\u001b[39m \u001b[39m10.0\u001b[39m \u001b[39m/\u001b[39m f\n\u001b[1;32m     32\u001b[0m     \u001b[39m# g.backward()\u001b[39;00m\n\u001b[1;32m     33\u001b[0m     \u001b[39m# apt, bpt, gpt = a, b, g\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[39m# assert abs(amg.grad - apt.grad.item()) < tol\u001b[39;00m\n\u001b[1;32m     41\u001b[0m     \u001b[39m# assert abs(bmg.grad - bpt.grad.item()) < tol\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m test_more_ops()\n",
      "Cell \u001b[0;32mIn[7], line 15\u001b[0m, in \u001b[0;36mtest_more_ops\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m g \u001b[39m=\u001b[39m f \u001b[39m/\u001b[39m [\u001b[39m2.0\u001b[39m]\n\u001b[1;32m     14\u001b[0m g \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m [\u001b[39m10.0\u001b[39m] \u001b[39m/\u001b[39m f\n\u001b[0;32m---> 15\u001b[0m g\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     16\u001b[0m \u001b[39m# amg, bmg, gmg = a, b, g\u001b[39;00m\n\u001b[1;32m     18\u001b[0m a \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mTensor([\u001b[39m-\u001b[39m\u001b[39m4.0\u001b[39m])\u001b[39m.\u001b[39mdouble()\n",
      "File \u001b[0;32m~/work/gradual/gradual/engine.py:184\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgrad \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mones(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mshape)\n\u001b[1;32m    183\u001b[0m \u001b[39mfor\u001b[39;00m v \u001b[39min\u001b[39;00m \u001b[39mreversed\u001b[39m(topo):\n\u001b[0;32m--> 184\u001b[0m   v\u001b[39m.\u001b[39;49m_backward()\n",
      "File \u001b[0;32m~/work/gradual/gradual/engine.py:126\u001b[0m, in \u001b[0;36mTensor.__mul__.<locals>._backward\u001b[0;34m()\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_backward\u001b[39m():\n\u001b[1;32m    125\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgrad \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m other\u001b[39m.\u001b[39mdata \u001b[39m*\u001b[39m out\u001b[39m.\u001b[39mgrad\n\u001b[0;32m--> 126\u001b[0m   other\u001b[39m.\u001b[39;49mgrad \u001b[39m+\u001b[39;49m\u001b[39m=\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata \u001b[39m*\u001b[39;49m out\u001b[39m.\u001b[39;49mgrad\n",
      "\u001b[0;31mValueError\u001b[0m: non-broadcastable output operand with shape () doesn't match the broadcast shape (1,)"
     ]
    }
   ],
   "source": [
    "def test_more_ops():\n",
    "\n",
    "    a = Tensor([-4.0])\n",
    "    b = Tensor([2.0])\n",
    "    c = a + b\n",
    "    d = a * b + b**[3]\n",
    "    c += c + [1]\n",
    "    c += [1] + c + (-a)\n",
    "    d += d * [2] + (b + a).relu()\n",
    "    d += [3] * d + (b - a).relu()\n",
    "    e = c - d\n",
    "    f = e**[2]\n",
    "    g = f / [2.0]\n",
    "    g += [10.0] / f\n",
    "    g.backward()\n",
    "    # amg, bmg, gmg = a, b, g\n",
    "\n",
    "    a = torch.Tensor([-4.0]).double()\n",
    "    b = torch.Tensor([2.0]).double()\n",
    "    a.requires_grad = True\n",
    "    b.requires_grad = True\n",
    "    c = a + b\n",
    "    d = a * b + b**3\n",
    "    c = c + c + 1\n",
    "    c = c + 1 + c + (-a)\n",
    "    d = d + d * 2 + (b + a).relu()\n",
    "    d = d + 3 * d + (b - a).relu()\n",
    "    e = c - d\n",
    "    f = e**2\n",
    "    g = f / 2.0\n",
    "    g = g + 10.0 / f\n",
    "    # g.backward()\n",
    "    # apt, bpt, gpt = a, b, g\n",
    "\n",
    "\n",
    "    # tol = 1e-6\n",
    "    # # forward pass went well\n",
    "    # assert abs(gmg.data - gpt.data.item()) < tol\n",
    "    # # backward pass went well\n",
    "    # assert abs(amg.grad - apt.grad.item()) < tol\n",
    "    # assert abs(bmg.grad - bpt.grad.item()) < tol\n",
    "\n",
    "test_more_ops()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123\n"
     ]
    }
   ],
   "source": [
    "def test_more_ops():\n",
    "    a = Tensor([-4.0])\n",
    "    b = Tensor([2.0])\n",
    "    c = a + b\n",
    "    c.backward()\n",
    "    # d = a * b + b**[3]\n",
    "    # c += c + [1]\n",
    "    # c += [1] + c + (-a)\n",
    "    # d += d * [2] + (b + a).relu()\n",
    "    # d += [3] * d + (b - a).relu()\n",
    "    # e = c - d\n",
    "    # f = e**[2]\n",
    "    # g = f / [2.0]\n",
    "    # g += [10.0] / f\n",
    "    # g.backward()\n",
    "    # amg, bmg, gmg = a, b, g\n",
    "\n",
    "\n",
    "test_more_ops()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Value(data=[0.5], grad=[0.], label=)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tensor([2.0])**-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def teste():# a very simple example\n",
    "    x = Value(1.0, label='x')\n",
    "    y = (x * 2 + 1).relu() \n",
    "    y.label='y'\n",
    "    # y.backward()\n",
    "    draw_dot(y)\n",
    "teste()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-4.], dtype=torch.float64, requires_grad=True)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "a = torch.Tensor([-4.0]).double()\n",
    "b = torch.Tensor([2.0]).double()\n",
    "a.requires_grad = True\n",
    "b.requires_grad = True\n",
    "# c = a + b\n",
    "# d = a * b + b**3\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sympy import *\n",
    "\n",
    "x, y = symbols('x y')\n",
    "init_printing(use_unicode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAA0AAAAPCAYAAAA/I0V3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAABJ0AAASdAHeZh94AAAAi0lEQVR4nO3SIQoCYRQE4E+xajYbxObewGjdYBTMRmGj8PgP4zkM3kMQjEb7Wv6wrC6sxeTACzO8YSbMoK5r32LUJCmlDVYosMQYp4jYdppwzM9P3LH4lDRs8QPmmGDfq15EnBtVuzxvSb3wN/3cNGgONqVUosx0ijWuuGTtERFVe3sFdi1tlg9uqF5xyRu/uhi7owAAAABJRU5ErkJggg==",
      "text/latex": [
       "$\\displaystyle 1$"
      ],
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "diff(x+y, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAA0AAAAQCAYAAADNo/U5AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAABJ0AAASdAHeZh94AAABFElEQVR4nJXSvUpcURTF8d+oleYJxIhgYd5AX0BIY2kzhZ2NWhjUSEDc7CqN2mgIFhYWPoDv4AcykGJgansR0cYUgmMxM3K93BHdzT6cs/6ss84+tXa77bM11Ftk5hp2sB4Ru2VhZk6hiauBwv5Zt8/0MdjHIFaK0D/8x3SFyzxm8Scimq9QRDyhga+ZOVoARrCHG2zDgLd1XnHFbYxhMyIe3oOmuy7f8AOXOO6JytAF2gWng2745Yh4nU2tPKfMbGECizjB34hYKmrKTnSefhiHuMVWWVAF9XJ9wa+IuPsIdN3tDRxVnFdCG3hWCt8Xysw65nTCN6oAGMrMcdQxiQW08LMfQOeXf8dv3OMUqxHx+B70AosVT5+dsfWCAAAAAElFTkSuQmCC",
      "text/latex": [
       "$\\displaystyle y$"
      ],
      "text/plain": [
       "y"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff(x*y, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAADUAAAAVCAYAAADmSqZGAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAABJ0AAASdAHeZh94AAADOElEQVR4nN3XXYhVZRQG4GfGiCghCCKI/iihgsKKTC9KKNCkEBuHgiTrQqJI6ceKUsrViv7TKahBTCIi6iJkrDCiAi/EnGT6UzCKCG+GrMzKi8qUnC72LrfbM6c5s3Euem++w1rfWvt991rfOt/uGhkZ8X/DMU2CM3MYfRHRV7FdhK24OCK+bEZvfGgkCoOYVrM9h7VNBWXmKfgO/RFxZyex3U0erCYqM3sxFdEwL8xT8FvfaWDTSn2MVZl5En7DM3g0IvY0zAs92INNnQYeJiozP8As9EbEQMXehVdwC56OiAdL16fYj0txCQ6gv5bzXqzEfRGxqk4gM8/FdmyNiJml7URchTci4q9O+dXb734cxGOZOaliX1kGrK0IEhF/4nPMxfKS+IFazs3lOqMuqMQLmIQlFdu1OBYDtb1j4neYqIjYhtdwPhZCZi7HUryJ21uQGsRiDEbEhhb+z/AHptcdmXm94s33R8T2iqtH0c4fjodfq0HxEPbhkcxcgsfxPhZGxMEW+79QvL2lLXzKyg3h9Mw8tSLoBPThR6yo2I/DHLwXEfvGw+8IURExjOdxpqI1tmB+ROxvRRo3YU1E7BjFDx+Va7UFV+A0PBAReyv22ZhslKk3Fn6jTb/dld+LIuL3qjMzu3EyFuEC3NBGEIdETcdAZp6HexSt+2ptb49i+LzbJl9bfkdUKjNvVBy870vTXS2SzsQuRV/3RsQvbQhQvM0Rhyr1omI4LI6If+9p5eGfi4216nXEr6t698vMa/AWvlaM1E2Yggsj4qv/IN4WmbkDZ+FWvI7VEXFHbc+V2IjbIuKlFjnGxK+7EnA51mEYsyNiNx5WtOhTTQSV2IzjsQY/KQ58HfMVQ+ftFoLGzK+7DJiKDdiLWRGxCyJiHT7BvMy8oqGof87VZCyLiJ9b7LkOWyLih5qgjvh1Z+YUxUgcwdUR8W3tQcvK9dlGkthZrkN4ue7MzGmKabi+Zu+YX9dEfU9l5juKm8KMiBhq4X+iJHh2ROys+ztB01v6mJCZCxRTbXUrQSV6sK2pII5ipTLzDCzAObgZ3+Cy+n/K0UDTT492mIMn8atimt09EYKYwDM1kfgbpBpgPOaUleMAAAAASUVORK5CYII=",
      "text/latex": [
       "$\\displaystyle \\frac{x^{y} y}{x}$"
      ],
      "text/plain": [
       " y  \n",
       "x ‚ãÖy\n",
       "‚îÄ‚îÄ‚îÄ‚îÄ\n",
       " x  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff(x**y, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAA0AAAAQCAYAAADNo/U5AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAABJ0AAASdAHeZh94AAABE0lEQVR4nJXSv0rcURDF8c8uVop/QLBKQBT1DYxglQQkL2EfFARri2EEWwtFH8An0NYmVSRvoK4I6VKZICJ2bgrvyt0fu6CnOXBnvjPD5bS63a73aqT5kJkfsItvmMYfnCIj4h+06k2ZOY8LzOAMV1jGZ1xjNSLumpuOC7AVEYfVsH1sYw/f21VhDmv4jaPGsMAj1jNzrF0VvhQ/j4jnPiLiAT8xipUaWireaX5O0U3xxRqaLH4/BOq9T7WHNAxSq3i3hnqTJg3WRK+vhq6LLw6BFop3auhH8bXM7Ds7M8exiif8ei1GxC3OMYvNxpbEGE4i4rGZiA0vMTrIzK+4xCcvMepgh0b2yikfDQ/s34HQW/Qfnq1S3HXUdK4AAAAASUVORK5CYII=",
      "text/latex": [
       "$\\displaystyle 0$"
      ],
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff(x**4, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
